{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pickle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import math\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import gc\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/first_round_training_data.csv')\n",
    "test = pd.read_csv('../data/first_round_testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 6000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in test.columns if c!='Group']\n",
    "cat_feats = ['Attribute4',\n",
    "'Attribute5',\n",
    "'Attribute6',\n",
    "'Attribute7',\n",
    "'Attribute8',\n",
    "'Attribute9',\n",
    "'Attribute10',\n",
    "'Parameter5',\n",
    "'Parameter6',\n",
    "'Parameter7',\n",
    "'Parameter8',\n",
    "'Parameter9',\n",
    "'Parameter10']\n",
    "\n",
    "use_cate = [c for c in cat_feats if 'Para' in c]  #使用到的6个变量\n",
    "col_only_train = [c for c in test.columns if c != 'Group']  #训练集中的所有变量\n",
    "all_feat = [c for c in train.columns if c != 'Quality_label']  #数据的所有特征\n",
    "data = pd.concat([train,test])\n",
    "\n",
    "def nnq_encode(data,en_col,use_col):\n",
    "    data[en_col + '_nnq_of_' + use_col] = data[en_col].map( data.groupby([en_col])[use_col].nunique() )\n",
    "    features.append( en_col + '_nnq_of_' + use_col )\n",
    "    return data\n",
    "\n",
    "# for en_col in use_cate:\n",
    "#     for use_col in cat_feats:\n",
    "#         if en_col != use_col:\n",
    "#             data = nnq_encode(data,en_col,use_col)\n",
    "# for en_col in use_cate:\n",
    "#     for use_col in use_cate:\n",
    "#         if en_col != use_col:\n",
    "#             colname =  en_col +'_count_' + use_col\n",
    "#             features.append( colname)\n",
    "#             data[ colname] = data[en_col].astype(str) + \"|\" + data[use_col].astype(str)\n",
    "#             data[ colname] = data.groupby([ colname ])[colname].transform('count')\n",
    "# for en_col in use_cate:\n",
    "#     for use_col in all_feat:\n",
    "#         if en_col != use_col:\n",
    "#             colname =  en_col +'_mean_' + use_col\n",
    "#             features.append( colname)\n",
    "#             data[ colname] = data[en_col].map( data.groupby([en_col])[use_col].mean() )\n",
    "#             colname =  en_col +'_std_' + use_col\n",
    "#             features.append( colname)\n",
    "#             data[ colname] = data[en_col].map( data.groupby([en_col])[use_col].std() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classMap = {'Excellent':0,\n",
    "'Good':1,\n",
    "'Pass':2,\n",
    "'Fail':3,}\n",
    "tr_index = ~data.Quality_label.isnull()\n",
    "train_df = data[tr_index][use_cate +['Quality_label']].reset_index(drop=True)\n",
    "train_df['Quality_label'] = train_df['Quality_label'].map(classMap)\n",
    "\n",
    "test_df = data[~tr_index].reset_index(drop=True)\n",
    "id_test = test_df.Group.values\n",
    "\n",
    "\n",
    "X_train = train_df[use_cate]    \n",
    "y = train_df.Quality_label\n",
    "X_test = test_df[use_cate]\n",
    "del train,test\n",
    "del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>147.608373</td>\n",
       "      <td>38.186345</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.601749</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>51.130326</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>69.233685</td>\n",
       "      <td>0.080920</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.181860</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>1.098102</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012085</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>524.327396</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004062</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>14.556483</td>\n",
       "      <td>0.786945</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.438449</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>1.232559</td>\n",
       "      <td>2.882699</td>\n",
       "      <td>0.610757</td>\n",
       "      <td>1.600654</td>\n",
       "      <td>0.464037</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48159.917401</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>14.863813</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>1.434060</td>\n",
       "      <td>0.314162</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.456601</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>52.381578</td>\n",
       "      <td>20.625283</td>\n",
       "      <td>366.074831</td>\n",
       "      <td>1.434060</td>\n",
       "      <td>0.258497</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>4.784654</td>\n",
       "      <td>31.916672</td>\n",
       "      <td>20.672388</td>\n",
       "      <td>1.284806</td>\n",
       "      <td>0.175007</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Parameter1  Parameter10  Parameter2  Parameter3  Parameter4  Parameter5  \\\n",
       "0      0.001660     1.010385    0.591013  147.608373   38.186345    0.000421   \n",
       "1      1.601749     1.010385    0.015052    0.035864   51.130326    0.000909   \n",
       "2      0.098039     1.010385   69.233685    0.080920    0.112265    0.000909   \n",
       "3     18.181860     1.010385    0.047325    0.018061    1.098102    0.000909   \n",
       "4      0.012085     1.010385    0.008749    0.005509  524.327396    0.000909   \n",
       "5      0.004062     1.010385   14.556483    0.786945    0.010545    0.000525   \n",
       "6      0.438449     0.010192    1.232559    2.882699    0.610757    1.600654   \n",
       "7  48159.917401     0.010192    0.002987   14.863813    0.063287    1.434060   \n",
       "8      1.456601     0.010192   52.381578   20.625283  366.074831    1.434060   \n",
       "9      0.000109     0.010192    4.784654   31.916672   20.672388    1.284806   \n",
       "\n",
       "   Parameter6   Parameter7  Parameter8  Parameter9  \n",
       "0    0.000612  2286.523413    0.035407    0.593081  \n",
       "1    0.002397  2286.523413    0.035407    0.593081  \n",
       "2    0.001972  2286.523413    0.035407    0.593081  \n",
       "3    0.002397  2286.523413    0.035407    0.593081  \n",
       "4    0.002397  2286.523413    0.035407    0.593081  \n",
       "5    0.001623  2286.523413    0.035407    0.593081  \n",
       "6    0.464037     0.600827   17.850021    0.051850  \n",
       "7    0.314162     0.600827   17.850021    0.051850  \n",
       "8    0.258497     0.600827   17.850021    0.051850  \n",
       "9    0.175007     0.600827   17.850021    0.051850  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's multi_logloss: 1.17429\ttrain's f1_weighted: 0.298003\tvalid's multi_logloss: 1.21025\tvalid's f1_weighted: 0.263807\n",
      "[100]\ttrain's multi_logloss: 1.09496\ttrain's f1_weighted: 0.545342\tvalid's multi_logloss: 1.16197\tvalid's f1_weighted: 0.443071\n",
      "[150]\ttrain's multi_logloss: 1.0392\ttrain's f1_weighted: 0.59546\tvalid's multi_logloss: 1.13434\tvalid's f1_weighted: 0.476635\n",
      "[200]\ttrain's multi_logloss: 0.998146\ttrain's f1_weighted: 0.618237\tvalid's multi_logloss: 1.11962\tvalid's f1_weighted: 0.496565\n",
      "[250]\ttrain's multi_logloss: 0.963889\ttrain's f1_weighted: 0.631733\tvalid's multi_logloss: 1.11221\tvalid's f1_weighted: 0.494446\n",
      "[300]\ttrain's multi_logloss: 0.934651\ttrain's f1_weighted: 0.645498\tvalid's multi_logloss: 1.10827\tvalid's f1_weighted: 0.49552\n",
      "[350]\ttrain's multi_logloss: 0.908083\ttrain's f1_weighted: 0.659653\tvalid's multi_logloss: 1.10586\tvalid's f1_weighted: 0.496744\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttrain's multi_logloss: 0.951707\ttrain's f1_weighted: 0.636086\tvalid's multi_logloss: 1.11055\tvalid's f1_weighted: 0.499486\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's multi_logloss: 1.17405\ttrain's f1_weighted: 0.295894\tvalid's multi_logloss: 1.21598\tvalid's f1_weighted: 0.263378\n",
      "[100]\ttrain's multi_logloss: 1.09444\ttrain's f1_weighted: 0.539307\tvalid's multi_logloss: 1.16851\tvalid's f1_weighted: 0.431353\n",
      "[150]\ttrain's multi_logloss: 1.03832\ttrain's f1_weighted: 0.593431\tvalid's multi_logloss: 1.14274\tvalid's f1_weighted: 0.464331\n",
      "[200]\ttrain's multi_logloss: 0.996615\ttrain's f1_weighted: 0.622972\tvalid's multi_logloss: 1.12975\tvalid's f1_weighted: 0.478473\n",
      "[250]\ttrain's multi_logloss: 0.9617\ttrain's f1_weighted: 0.639641\tvalid's multi_logloss: 1.12224\tvalid's f1_weighted: 0.484578\n",
      "[300]\ttrain's multi_logloss: 0.931836\ttrain's f1_weighted: 0.653628\tvalid's multi_logloss: 1.1178\tvalid's f1_weighted: 0.491941\n",
      "[350]\ttrain's multi_logloss: 0.90584\ttrain's f1_weighted: 0.665842\tvalid's multi_logloss: 1.11601\tvalid's f1_weighted: 0.492154\n",
      "[400]\ttrain's multi_logloss: 0.881467\ttrain's f1_weighted: 0.678706\tvalid's multi_logloss: 1.1155\tvalid's f1_weighted: 0.494932\n",
      "[450]\ttrain's multi_logloss: 0.85904\ttrain's f1_weighted: 0.694503\tvalid's multi_logloss: 1.11607\tvalid's f1_weighted: 0.493879\n",
      "[500]\ttrain's multi_logloss: 0.838013\ttrain's f1_weighted: 0.706742\tvalid's multi_logloss: 1.11725\tvalid's f1_weighted: 0.492816\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttrain's multi_logloss: 0.875564\ttrain's f1_weighted: 0.684436\tvalid's multi_logloss: 1.1154\tvalid's f1_weighted: 0.497728\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's multi_logloss: 1.17562\ttrain's f1_weighted: 0.299682\tvalid's multi_logloss: 1.21137\tvalid's f1_weighted: 0.276505\n",
      "[100]\ttrain's multi_logloss: 1.09636\ttrain's f1_weighted: 0.535355\tvalid's multi_logloss: 1.1643\tvalid's f1_weighted: 0.446573\n",
      "[150]\ttrain's multi_logloss: 1.04056\ttrain's f1_weighted: 0.593327\tvalid's multi_logloss: 1.13731\tvalid's f1_weighted: 0.490422\n",
      "[200]\ttrain's multi_logloss: 0.99855\ttrain's f1_weighted: 0.61896\tvalid's multi_logloss: 1.12372\tvalid's f1_weighted: 0.499926\n",
      "[250]\ttrain's multi_logloss: 0.96365\ttrain's f1_weighted: 0.638029\tvalid's multi_logloss: 1.11732\tvalid's f1_weighted: 0.505539\n",
      "[300]\ttrain's multi_logloss: 0.933879\ttrain's f1_weighted: 0.654748\tvalid's multi_logloss: 1.11523\tvalid's f1_weighted: 0.499418\n",
      "[350]\ttrain's multi_logloss: 0.906948\ttrain's f1_weighted: 0.670092\tvalid's multi_logloss: 1.11424\tvalid's f1_weighted: 0.501896\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttrain's multi_logloss: 0.95562\ttrain's f1_weighted: 0.641977\tvalid's multi_logloss: 1.11646\tvalid's f1_weighted: 0.507183\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's multi_logloss: 1.17547\ttrain's f1_weighted: 0.286349\tvalid's multi_logloss: 1.20724\tvalid's f1_weighted: 0.279731\n",
      "[100]\ttrain's multi_logloss: 1.09717\ttrain's f1_weighted: 0.540506\tvalid's multi_logloss: 1.1583\tvalid's f1_weighted: 0.453088\n",
      "[150]\ttrain's multi_logloss: 1.04236\ttrain's f1_weighted: 0.596175\tvalid's multi_logloss: 1.13091\tvalid's f1_weighted: 0.481157\n",
      "[200]\ttrain's multi_logloss: 1.00085\ttrain's f1_weighted: 0.616824\tvalid's multi_logloss: 1.11568\tvalid's f1_weighted: 0.492882\n",
      "[250]\ttrain's multi_logloss: 0.965959\ttrain's f1_weighted: 0.632796\tvalid's multi_logloss: 1.10621\tvalid's f1_weighted: 0.504542\n",
      "[300]\ttrain's multi_logloss: 0.935751\ttrain's f1_weighted: 0.652528\tvalid's multi_logloss: 1.10129\tvalid's f1_weighted: 0.512211\n",
      "[350]\ttrain's multi_logloss: 0.908624\ttrain's f1_weighted: 0.668602\tvalid's multi_logloss: 1.09866\tvalid's f1_weighted: 0.512082\n",
      "[400]\ttrain's multi_logloss: 0.883834\ttrain's f1_weighted: 0.679602\tvalid's multi_logloss: 1.09784\tvalid's f1_weighted: 0.513182\n",
      "[450]\ttrain's multi_logloss: 0.861437\ttrain's f1_weighted: 0.693157\tvalid's multi_logloss: 1.09759\tvalid's f1_weighted: 0.509534\n",
      "[500]\ttrain's multi_logloss: 0.840603\ttrain's f1_weighted: 0.705434\tvalid's multi_logloss: 1.0981\tvalid's f1_weighted: 0.506597\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttrain's multi_logloss: 0.872462\ttrain's f1_weighted: 0.686016\tvalid's multi_logloss: 1.09736\tvalid's f1_weighted: 0.514856\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's multi_logloss: 1.17814\ttrain's f1_weighted: 0.295874\tvalid's multi_logloss: 1.20357\tvalid's f1_weighted: 0.265329\n",
      "[100]\ttrain's multi_logloss: 1.10134\ttrain's f1_weighted: 0.518988\tvalid's multi_logloss: 1.15096\tvalid's f1_weighted: 0.467379\n",
      "[150]\ttrain's multi_logloss: 1.04651\ttrain's f1_weighted: 0.585168\tvalid's multi_logloss: 1.12056\tvalid's f1_weighted: 0.503305\n",
      "[200]\ttrain's multi_logloss: 1.00595\ttrain's f1_weighted: 0.612593\tvalid's multi_logloss: 1.1035\tvalid's f1_weighted: 0.515493\n",
      "[250]\ttrain's multi_logloss: 0.972003\ttrain's f1_weighted: 0.627718\tvalid's multi_logloss: 1.09443\tvalid's f1_weighted: 0.513637\n",
      "[300]\ttrain's multi_logloss: 0.942559\ttrain's f1_weighted: 0.64505\tvalid's multi_logloss: 1.09044\tvalid's f1_weighted: 0.514239\n",
      "[350]\ttrain's multi_logloss: 0.916371\ttrain's f1_weighted: 0.657678\tvalid's multi_logloss: 1.08783\tvalid's f1_weighted: 0.522289\n",
      "[400]\ttrain's multi_logloss: 0.892094\ttrain's f1_weighted: 0.671675\tvalid's multi_logloss: 1.08661\tvalid's f1_weighted: 0.519062\n",
      "[450]\ttrain's multi_logloss: 0.869502\ttrain's f1_weighted: 0.68809\tvalid's multi_logloss: 1.08652\tvalid's f1_weighted: 0.522556\n",
      "[500]\ttrain's multi_logloss: 0.848231\ttrain's f1_weighted: 0.702864\tvalid's multi_logloss: 1.08643\tvalid's f1_weighted: 0.52024\n",
      "Early stopping, best iteration is:\n",
      "[418]\ttrain's multi_logloss: 0.883874\ttrain's f1_weighted: 0.677064\tvalid's multi_logloss: 1.08657\tvalid's f1_weighted: 0.523894\n"
     ]
    }
   ],
   "source": [
    "lgb_paras = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 32,\n",
    "        # 'lambda_l1': 0.01,\n",
    "        # 'lambda_l2': 10,\n",
    "        'num_class': 4,\n",
    "        'max_depth': -1,\n",
    "        'seed': 2019,\n",
    "        'feature_fraction': 0.8,\n",
    "        #         'bagging_fraction': 0.8,\n",
    "        #         'bagging_freq': 4,\n",
    "        'verbose': 1,\n",
    "        'device': 'gpu',\n",
    "        'gpu_device_id':'0',\n",
    "    }\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "all_preads = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2019, shuffle=True)\n",
    "def f1_weighted(preds, train_data):\n",
    "    y_true = train_data.label\n",
    "    preds = np.argmax(preds.reshape(4, -1), axis=0)\n",
    "    score = f1_score(y_true, preds, average='weighted')\n",
    "    return 'f1_weighted', score, True\n",
    "evals_result = {}\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X_train, y)):\n",
    "    train_x, test_x, train_y, test_y = X_train[use_cate].iloc[train_index], X_train[use_cate].iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    dtrain = lgb.Dataset(train_x, train_y)\n",
    "\n",
    "    dvalid = lgb.Dataset(test_x, test_y)\n",
    "#     clf = lgb.train(\n",
    "#         params=lgb_paras,\n",
    "#         train_set=dtrain,\n",
    "#         num_boost_round=10000,\n",
    "#         valid_sets=[dtrain, dvalid],\n",
    "#         evals_result=evals_result,\n",
    "#         early_stopping_rounds=100,\n",
    "#         valid_names=[\"train\", \"valid\"],\n",
    "#         # categorical_feature=cate_cols,\n",
    "#         verbose_eval=100)\n",
    "    \n",
    "    lgb_modelall = lgb.train(lgb_paras, dtrain,\n",
    "                             valid_sets=[dtrain, dvalid],\n",
    "                             num_boost_round=1000,\n",
    "                             early_stopping_rounds=100,\n",
    "                             valid_names=[\"train\", \"valid\"],\n",
    "                             evals_result=evals_result,\n",
    "                             verbose_eval=50,\n",
    "                             feval=f1_weighted)\n",
    "    pred = lgb_modelall.predict(X_test)\n",
    "    all_preads.append( pred )\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pread = np.mean(all_preads,axis=0)\n",
    "cols = ['Excellent ratio','Good ratio','Pass ratio','Fail ratio']\n",
    "\n",
    "sub_prob  = pd.DataFrame(mean_pread,columns=cols)\n",
    "len(sub_prob),len(id_test)\n",
    "sub_prob['Group'] = id_test\n",
    "\n",
    "sub_prob['Group'] = sub_prob['Group'].map(int)\n",
    "sub_prob = sub_prob.groupby([ 'Group'])[cols].median().reset_index()\n",
    "\n",
    "sub_prob.to_csv('../submission/lgb_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47844266, 0.26459496, 0.1909932 , 0.06596918])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preads[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parameter1',\n",
       " 'Parameter10',\n",
       " 'Parameter2',\n",
       " 'Parameter3',\n",
       " 'Parameter4',\n",
       " 'Parameter5',\n",
       " 'Parameter6',\n",
       " 'Parameter7',\n",
       " 'Parameter8',\n",
       " 'Parameter9']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
